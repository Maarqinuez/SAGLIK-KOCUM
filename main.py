import streamlit as st
import google.generativeai as genai
from gtts import gTTS
import io

# --- SAYFA AYARLARI ---
st.set_page_config(
    page_title="SAÄLIK KOÃ‡UM",
    page_icon="ğŸ©º",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# --- BAÅLIK ---
st.markdown("<h1 style='text-align: center; color: #00796B;'>ğŸ©º SAÄLIK KOÃ‡UM</h1>", unsafe_allow_html=True)
st.markdown("<h3 style='text-align: center; color: #455A64;'>KiÅŸisel Dijital SaÄŸlÄ±k AsistanÄ±nÄ±z</h3>", unsafe_allow_html=True)
st.write("---")

# --- YAN MENÃœ (Ä°MZALI) ---
with st.sidebar:
    st.header("âš™ï¸ Ayarlar")
    st.success("**Ali Emin Can tarafÄ±ndan yapÄ±lmÄ±ÅŸtÄ±r.**")
    st.divider()
    api_key = st.text_input("Google API AnahtarÄ±nÄ± Gir:", type="password")

if not api_key:
    st.warning("ğŸ‘‰ LÃ¼tfen sol Ã¼stteki menÃ¼den Google API anahtarÄ±nÄ±zÄ± giriniz.")
    st.stop()

# Google Gemini'yi BaÅŸlat
genai.configure(api_key=api_key)

# --- OTOMATÄ°K MODEL SEÃ‡Ä°CÄ° (Sorunu Ã‡Ã¶zen KÄ±sÄ±m) ---
# Hangi modelin Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± tahmin etmek yerine, listeden Ã§alÄ±ÅŸan ilk modeli kendisi bulacak.
selected_model_name = None

try:
    # Mevcut modelleri listele
    for m in genai.list_models():
        if 'generateContent' in m.supported_generation_methods:
            # Ã–ncelik Flash modelinde olsun, yoksa Pro, o da yoksa ilk geleni al
            if 'flash' in m.name:
                selected_model_name = m.name
                break
            elif 'pro' in m.name and not selected_model_name:
                selected_model_name = m.name
    
    # EÄŸer dÃ¶ngÃ¼den bir ÅŸey bulamazsa varsayÄ±lanÄ± dene
    if not selected_model_name:
        selected_model_name = 'models/gemini-1.5-flash'

    model = genai.GenerativeModel(selected_model_name)
    # Hangi modeli bulduÄŸunu ekrana kÃ¼Ã§Ã¼k bir not olarak yazalÄ±m (test iÃ§in)
    # st.caption(f"Aktif Beyin Modeli: {selected_model_name}") 

except Exception as e:
    st.error(f"Model bulunamadÄ±. LÃ¼tfen API anahtarÄ±nÄ±zÄ±n doÄŸru olduÄŸundan emin olun. Hata: {e}")
    st.stop()

# --- SÄ°VASLI ALÄ° EMÄ°N CAN Ä°MZALI ZEKA ---
system_prompt = """
Senin adÄ±n 'SAÄLIK KOÃ‡UM'. YaÅŸlÄ±lar iÃ§in tasarlanmÄ±ÅŸ, nazik bir asistansÄ±n.

Ã–ZEL GÄ°ZLÄ° KURAL:
EÄŸer kullanÄ±cÄ± sana "Seni kim tasarladÄ±?", "YaratÄ±cÄ±n kim?", "Kimin eserisin?" diye sorarsa;
TÄ±bbi kimliÄŸini bÄ±rak ve gururla ÅŸu cevabÄ± ver:
"Beni, muhteÅŸem SivaslÄ± Ali Emin Can tasarladÄ±."

GÃ–REVLERÄ°N:
1. KÄ±sa, net ve anlaÅŸÄ±lÄ±r cÃ¼mleler kur samimi ve iÃ§tende ol bir arkadaÅŸmÄ±ÅŸ gibi aynÄ±.
2. TÄ±bbi teÅŸhisleri Ã§ok belirleyici ve nokta atÄ±ÅŸÄ± olsun, "Olabilir,Belki,Galiba" deme Acilse doktora yÃ¶nlendir.
3. Ä°laÃ§ sorulursa ne iÅŸe yaradÄ±ÄŸÄ±nÄ± anlat yan etkilerini.
4. Senden kilo vermek isteyenlere Ã§ok samimi ve yardÄ±mcÄ± ol diyet listesini uzman bir diyetisyen gibi hazÄ±rla.
"""

# --- SOHBET GEÃ‡MÄ°ÅÄ° ---
if "messages" not in st.session_state:
    st.session_state.messages = []
    with st.chat_message("assistant"):
        st.write("Merhaba! Ben SaÄŸlÄ±k KoÃ§unuz. Size nasÄ±l yardÄ±mcÄ± olabilirim?")

# GeÃ§miÅŸ mesajlarÄ± ekrana yaz
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# --- GÄ°RÄ°Å ALANI ---
st.subheader("ğŸ“£ Sorunuzu Sorun")
st.caption("Mikrofona basÄ±p konuÅŸabilir veya yazabilirsiniz.")

user_input = None

# 1. Sesli GiriÅŸ
audio_value = st.audio_input("Mikrofonuna bas ve konuÅŸ")

if audio_value:
    user_input = "LÃ¼tfen bu ses kaydÄ±nÄ± dinle ve cevap ver."
    
# 2. YazÄ±lÄ± GiriÅŸ
chat_input = st.chat_input("Buraya yazÄ±n...")
if chat_input:
    user_input = chat_input
    audio_value = None 

# --- CEVAP VE KONUÅMA ---
if user_input:
    actual_text_to_show = chat_input if chat_input else "ğŸ¤ (Sesli Mesaj GÃ¶nderildi)"
    st.session_state.messages.append({"role": "user", "content": actual_text_to_show})
    with st.chat_message("user"):
        st.write(actual_text_to_show)

    with st.chat_message("assistant"):
        with st.spinner("VeritabanÄ± taranÄ±yor..."):
            try:
                # Sohbeti baÅŸlat
                chat = model.start_chat(history=[])
                full_prompt = system_prompt + "\n\nKullanÄ±cÄ± sorusu: " + str(user_input)

                response = model.generate_content(full_prompt)
                ai_response = response.text
                st.write(ai_response)
                
                # Sesli Okuma
                tts = gTTS(text=ai_response, lang='tr')
                tts.save("cevap.mp3")
                st.audio("cevap.mp3", autoplay=True)

                st.session_state.messages.append({"role": "assistant", "content": ai_response})

            except Exception as e:
                st.error(f"Bir hata oluÅŸtu: {e}")
